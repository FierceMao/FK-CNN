# FK-CNN | ä»é›¶å¼€å§‹çš„å·ç§¯ç¥ç»ç½‘ç»œ

> ğŸš€ A convolutional neural network implemented from scratch using only NumPy.

æ‰‹å†™å®ç°çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œä¸ä¾èµ– PyTorch / TensorFlowï¼Œä»…ä½¿ç”¨ NumPy å’Œ Matplotlibã€‚

---

## ğŸ§  Project Overview | é¡¹ç›®æ¦‚è§ˆ

This project builds a complete convolutional neural network pipeline step by step, starting from dataset loading, to building each layer (convolution, activation, pooling, fully connected, softmax), and assembling them into a functional model.

æœ¬é¡¹ç›®è‡ªåº•å‘ä¸Šæ„å»ºäº†å®Œæ•´çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ŒåŒ…æ‹¬ï¼šæ•°æ®åŠ è½½ã€å·ç§¯å±‚ã€æ¿€æ´»å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥å±‚ä¸ Softmax è¾“å‡ºå±‚ï¼Œå¹¶æ”¯æŒè®­ç»ƒä¸æ¨ç†æµç¨‹ã€‚

---

## ğŸ”¬ Theory Behind the Code | æ ¸å¿ƒåŸç†è®²è§£

### 1. Convolutional Layer | å·ç§¯å±‚

Performs feature extraction using sliding filters over input images.

* Each filter has learnable weights and bias.
* Output is computed as element-wise dot product of patch and filter.

**ä½œç”¨**ï¼šæå–å›¾åƒçš„å±€éƒ¨ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ç­‰ï¼‰ï¼Œä¿ç•™ç©ºé—´ç»“æ„ã€‚

### 2. Activation (ReLU)

Applies non-linearity: `ReLU(x) = max(0, x)`.

**ä½œç”¨**ï¼šå¼•å…¥éçº¿æ€§ï¼Œæé«˜æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ï¼ŒæŠ‘åˆ¶è´Ÿæ¿€æ´»ã€‚

### 3. Max Pooling

Reduces spatial resolution while retaining dominant features.

* Operates on small regions (e.g., 2x2)
* Keeps the maximum value

**ä½œç”¨**ï¼šé™ä½è®¡ç®—é‡ã€å‹ç¼©ç‰¹å¾å›¾å°ºå¯¸ã€å¢å¼ºä¸å˜æ€§ï¼ˆå¦‚æ—‹è½¬ã€å¹³ç§»ï¼‰ã€‚

### 4. Fully Connected Layer

Flattens and connects extracted features to output classes.

**ä½œç”¨**ï¼šç»¼åˆæ‰€æœ‰ç‰¹å¾ä¿¡æ¯ï¼Œè¿›è¡Œé«˜ç»´ç©ºé—´çš„çº¿æ€§å˜æ¢ï¼Œç”¨äºåˆ†ç±»ã€‚

### 5. Softmax + Cross Entropy

* Softmax normalizes output to probability distribution
* Cross Entropy measures prediction error w\.r.t. true labels

**ä½œç”¨**ï¼šå°†è¾“å‡ºæ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶è®¡ç®—æ¨¡å‹è¾“å‡ºä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ã€‚

---

## ğŸ“ Project Structure | é¡¹ç›®ç»“æ„

```
handmade_cnn/
â”œâ”€â”€ layers/                # Core layer implementations
â”‚   â”œâ”€â”€ conv.py           # Conv2D layer
â”‚   â”œâ”€â”€ activation.py     # ReLU layer
â”‚   â”œâ”€â”€ pool.py           # MaxPool2D
â”‚   â””â”€â”€ fc.py             # Fully connected layer
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cnn.py            # CNN model assembly
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger_util.py    # Logger setup
â”œâ”€â”€ dataset.py            # MNIST loader
â”œâ”€â”€ train.py              # Training loop
â”œâ”€â”€ test.py               # Evaluation script
â”œâ”€â”€ requirements.txt      # Pip dependencies
â””â”€â”€ README.md             # This file
```

---

## âš™ï¸ Installation | å®‰è£…æ–¹æ³•

### Option : Use pip + venv

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ§ª Usage | ä½¿ç”¨æ–¹æ³•

### Step 1: Load and preprocess data

```bash
python main.py
```

---

## ğŸ“Œ Features | ç‰¹æ€§

* âœ… Handwritten convolution implementation (vectorized)
* âœ… Max pooling with zero-padding and edge handling
* âœ… Fully connected layer with dynamic shape adaptation
* âœ… Softmax + cross-entropy loss with label separation
* âœ… Supports flexible padding, stride, and batch fetching
* âœ… Structured logging & modular architecture

---

## ğŸ” Requirements | ç¯å¢ƒè¦æ±‚

* Python >= 3.8
* NumPy >= 1.24.0
* Matplotlib >= 3.7.0

---

## ğŸ§‘â€ğŸ’» Author | ä½œè€…

**STEVEN ZHAO**
Handcrafted with â¤ï¸ in 2025-07

---

## ğŸ“„ License | å¼€æºåè®®

GPL License v3.0.

---

æœ¬é¡¹ç›®é€‚åˆä½œä¸ºåˆå­¦è€…æ·±å…¥ç†è§£ CNN åŸç†çš„ç»ƒä¹ é¡¹ç›®ï¼Œä¹Ÿå¯æ‹“å±•ç”¨äºæ›´å¤æ‚çš„å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚

æ¬¢è¿ Star / Fork / æäº¤ Pull Requestï¼

---

*If you'd like a Chinese-only or English-only version, please let me know!*
